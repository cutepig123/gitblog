# [llama3测试](https://github.com/cutepig123/gitblog/issues/71)

llama3测试

安装软件
ollama for windows
docker for windows


启动ollama服务器 windows
set OLLAMA_HOST=0.0.0.0:8080
ollama serve

调用ollama
1) 直接调用ollama
curl http://192.168.1.138:8080/api/generate -d '{
  "model": "llama3",
  "prompt":"Why is the sky blue?"
}'

2) 通过chatollama掉用
d:\
cd code\chatollama
docker compose up

本地数据索引
下载nomic-embed-text:latest，然后在本地数据库的embedding里面敲进去nomic-embed-text:latest

https://github.com/ollama/ollama/issues/703
https://docs.docker.com/desktop/wsl/
